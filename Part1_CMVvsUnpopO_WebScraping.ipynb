{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e36be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a753d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date = datetime.today()\n",
    "posts = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1ac176",
   "metadata": {},
   "source": [
    "***Process used for data collection***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d774d76c",
   "metadata": {},
   "source": [
    "- Never run this again, unless trying to duplicate this work. Full list of queries and the date at which they were made can be found in AllQueries.txt, accompanying this file."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8d636ee",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "#credit to: Gwen Rathgeber\n",
    "# establish parameters\n",
    "subreddits = ['unpopularopinion', 'changemyview']\n",
    "kind = \"submission\"\n",
    "\n",
    "# Establish URL base\n",
    "BASE_URL = f\"https://api.pushshift.io/reddit/search/{kind}\" # also known as the \"API endpoint\" \n",
    "\n",
    "for subreddit in subreddits:\n",
    "    posts[subreddit] = []\n",
    "    day = 1\n",
    "    cumulative_posts = 0\n",
    "    while cumulative_posts < 15000:\n",
    "        stem = f\"{BASE_URL}?subreddit={subreddit}&size=100\"\n",
    "        URL = f\"{stem}&after={day}d\"\n",
    "        print(\"Querying from: \" + URL)\n",
    "        try:\n",
    "            res = requests.get(URL)\n",
    "            assert res.status_code == 200\n",
    "            json = res.json()['data']\n",
    "            df = pd.DataFrame(json)\n",
    "            posts[subreddit].append(df)\n",
    "\n",
    "            cumulative_posts += df.shape[0]\n",
    "\n",
    "            final_date_pulled = datetime.utcfromtimestamp(df.iloc[-1, df.columns.get_loc('created_utc')])\n",
    "            increment = (last_date - final_date_pulled).days + 1\n",
    "            increment = increment if increment > 0 else 1\n",
    "            day += increment\n",
    "            last_date = final_date_pulled\n",
    "        except:\n",
    "            print(f'Scrape for {URL}, {day} failed')\n",
    "        \n",
    "        time.sleep(2)\n",
    "\n",
    "print(\"Query complete!\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "acad285f",
   "metadata": {},
   "source": [
    "change_frame = pd.concat(posts['changemyview'])\n",
    "opinion_frame = pd.concat(posts['unpopularopinion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf54b58",
   "metadata": {},
   "source": [
    "- Save scraped data."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f266f82d",
   "metadata": {},
   "source": [
    "change_frame.to_csv('data/raw_changemyview_initial_scrape')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "845c7ff1",
   "metadata": {},
   "source": [
    "opinion_frame.to_csv('data/raw_unpopularopinion_initial_scrape')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78bfc7f",
   "metadata": {},
   "source": [
    "- On to part 2 ->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
