{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ca9b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "from skopt import BayesSearchCV\n",
    "from scipy.stats import uniform, loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a45cacad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(tn, fp, fn, tp, metric = ['accuracy']):\n",
    "    answers = {}\n",
    "    \n",
    "    if 'accuracy' in metric or 'all' in metric:\n",
    "        answers['accuracy'] = (tp + tn) / (tn + fn + fp + tp)\n",
    "    if 'sensitivity' in metric  or 'all' in metric:\n",
    "        answers['sensitivity'] = tp / (tp + fn)\n",
    "    if 'specificity' in metric  or 'all' in metric:\n",
    "        answers['specificity'] = tn / (tn + fp)\n",
    "    if 'f1' in metric or 'all' in metric:\n",
    "        answers['f1'] = tp / (tp + .5*(fp + fn))\n",
    "\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57911910",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cleaned_cmv&unpop_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52fddfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36efc47",
   "metadata": {},
   "source": [
    "***Data Engineering***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a31265a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unpopularopinion    0.563229\n",
       "changemyview        0.436771\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadd6a83",
   "metadata": {},
   "source": [
    "- Set changemyview to be the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abcbec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subreddit'] = df['subreddit'].map(lambda x: 1 if x == 'changemyview' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ef6742",
   "metadata": {},
   "source": [
    "- Scrub URLs and CMVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf0f61f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrub_text(string):\n",
    "    remove_cmv_url = r'^([Cc]{1}[Mm]{1}[Vv]{1}[:]{0,1})|([Ww]{3}[^\\s]+)|([^\\s]+[\\.]{1}[Cc]{1}[Oo]{1}[Mm]{1})$'\n",
    "    return re.sub(remove_cmv_url, '', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9a4f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].map(scrub_text)\n",
    "df['selftext'] = df['selftext'].map(scrub_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95acd18f",
   "metadata": {},
   "source": [
    "- Lemmatize text fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c87bd496",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68e1f097",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de31d6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma_map(in_string):  \n",
    "    to_lemma = tokenizer.tokenize(in_string)\n",
    "    return \" \".join([lemmatizer.lemmatize(token.lower()) for token in to_lemma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0a15194",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].map(lemma_map)\n",
    "df['selftext'] = df['selftext'].map(lemma_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86391c33",
   "metadata": {},
   "source": [
    "- Add sentiment analysis columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "384e7d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = zip(list(df['title']), list(df['selftext']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beab5480",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac9ed701",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = []    \n",
    "\n",
    "for title, tweet in corpus:\n",
    "    scores = sia.polarity_scores(title + \" \" + tweet)\n",
    "    sentiment.append(scores)\n",
    "\n",
    "sents = pd.DataFrame(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d47e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, sents], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05a3bcb",
   "metadata": {},
   "source": [
    "- Change column names so that there won't be a collision with vectorized columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f94b2ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'author': 'author_username', 'id': 'author_id', 'selftext': 'post_text', 'score': 'post_score', 'subreddit': 'post_subreddit', 'title': 'post_title', 'neg': 'neg_sentiment', 'pos': 'pos_sentiment', 'neu': 'neu_sentiment', 'compound': 'comp_sentiment'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120fa522",
   "metadata": {},
   "source": [
    "- Add training column for fitting purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19045d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['training_set'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c204c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = df.columns.tolist()\n",
    "x_list.remove('post_subreddit')\n",
    "X = df[x_list]\n",
    "y = df['post_subreddit']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbba65b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avanyali\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_train['training_set'] = X_train['training_set'].map(lambda x: 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ee9f331",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total = pd.concat([X_train, y_train], axis = 1)\n",
    "test_total = pd.concat([X_test, y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606d05e7",
   "metadata": {},
   "source": [
    "- Identify best parameters for vectorizer. Code credit to lesson 'advanced hyperparameter search'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04b33751",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = 'english')),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'cvec__max_features': Integer(100, 3000),\n",
    "    'cvec__min_df': Integer(1, 5),\n",
    "    'cvec__max_df': Real(.5,1, prior='uniform')\n",
    "}\n",
    "\n",
    "cvec_bs = BayesSearchCV(estimator = pipe,\n",
    "                     search_spaces = params,\n",
    "                     scoring = 'f1_weighted',\n",
    "                     n_iter = 50,\n",
    "                     cv = 5,\n",
    "                     refit = True,\n",
    "                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5bf85f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_post = X_train['post_title'] + \" \" + X_train['post_text']\n",
    "test_text_post = X_test['post_title'] + \" \" + X_test['post_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc49f54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=Pipeline(steps=[('cvec',\n",
       "                                         CountVectorizer(stop_words='english')),\n",
       "                                        ('mnb', MultinomialNB())]),\n",
       "              random_state=42, scoring='f1_weighted',\n",
       "              search_spaces={'cvec__max_df': Real(low=0.5, high=1, prior='uniform', transform='identity'),\n",
       "                             'cvec__max_features': Integer(low=100, high=3000, prior='uniform', transform='identity'),\n",
       "                             'cvec__min_df': Integer(low=1, high=5, prior='uniform', transform='identity')})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec_bs.fit(train_text_post, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b592e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cvec_bs.predict(test_text_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e40a79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('cvec__max_df', 0.7933144337167336),\n",
       "             ('cvec__max_features', 1537),\n",
       "             ('cvec__min_df', 1)])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec_bs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3effbf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fae5996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7899794097460535,\n",
       " 'sensitivity': 0.7242733699921445,\n",
       " 'specificity': 0.8409506398537477,\n",
       " 'f1': 0.750814332247557}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(tn, fp, fn, tp, metric = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f1e543",
   "metadata": {},
   "source": [
    "- Vectorize words and add to dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d17dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = cvec_bs.best_estimator_['cvec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30d74a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcv_train = cvec.fit_transform(train_total['post_title'] + \" \" + train_total['post_text'])\n",
    "Xcv_test = cvec.transform(test_total['post_title'] + \" \" + test_total['post_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f070f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xcv_train = pd.DataFrame(Xcv_train.todense(), columns = cvec.get_feature_names())\n",
    "df_xcv_test = pd.DataFrame(Xcv_test.todense(), columns = cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28da43c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xcv_train.reset_index(inplace = True)\n",
    "df_xcv_test.reset_index(inplace = True)\n",
    "train_total.reset_index(inplace = True)\n",
    "test_total.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b75c0364",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_vecs = pd.concat([train_total, df_xcv_train], axis = 1)\n",
    "test_with_vecs = pd.concat([test_total, df_xcv_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a995bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_with_vecs, test_with_vecs], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c764ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f323a44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'index', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fc42f2",
   "metadata": {},
   "source": [
    "- Save engineered file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef99fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/engineered_cmv&unpop_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ed9f9",
   "metadata": {},
   "source": [
    "- On to part 4 ->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
