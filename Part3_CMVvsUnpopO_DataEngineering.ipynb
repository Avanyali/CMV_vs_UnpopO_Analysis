{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e5ccb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "from skopt import BayesSearchCV\n",
    "from scipy.stats import uniform, loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d658462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(tn, fp, fn, tp, metric = ['accuracy']):\n",
    "    answers = {}\n",
    "    \n",
    "    if 'accuracy' in metric or 'all' in metric:\n",
    "        answers['accuracy'] = (tp + tn) / (tn + fn + fp + tp)\n",
    "    if 'sensitivity' in metric  or 'all' in metric:\n",
    "        answers['sensitivity'] = tp / (tp + fn)\n",
    "    if 'specificity' in metric  or 'all' in metric:\n",
    "        answers['specificity'] = tn / (tn + fp)\n",
    "    if 'f1' in metric or 'all' in metric:\n",
    "        answers['f1'] = tp / (tp + .5*(fp + fn))\n",
    "\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6d19500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cleaned_cmv&unpop_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "430b9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38880761",
   "metadata": {},
   "source": [
    "***Data Engineering***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f693c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unpopularopinion    0.563229\n",
       "changemyview        0.436771\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a76c25",
   "metadata": {},
   "source": [
    "- Set changemyview to be the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05967a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subreddit'] = df['subreddit'].map(lambda x: 1 if x == 'changemyview' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce56f27",
   "metadata": {},
   "source": [
    "- Add sentiment analysis columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76fdb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(df['selftext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0bb0702",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f5adf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = []    \n",
    "\n",
    "for tweet in corpus:\n",
    "    scores = sia.polarity_scores(tweet)\n",
    "    sentiment.append(scores)\n",
    "\n",
    "sents = pd.DataFrame(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23d932a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, sents], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d5f72e",
   "metadata": {},
   "source": [
    "- Change column names so that there won't be a collision with vectorized columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6e3e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'author': 'author_username', 'id': 'author_id', 'selftext': 'post_text', 'score': 'post_score', 'subreddit': 'post_subreddit', 'title': 'post_title', 'neg': 'neg_sentiment', 'pos': 'pos_sentiment', 'neu': 'neu_sentiment', 'compound': 'comp_sentiment'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf41a50",
   "metadata": {},
   "source": [
    "- Add training column for fitting purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9d02092",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['training_set'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a5c1646",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = df.columns.tolist()\n",
    "x_list.remove('post_subreddit')\n",
    "X = df[x_list]\n",
    "y = df['post_subreddit']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "342b044e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avanyali\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_train['training_set'] = X_train['training_set'].map(lambda x: 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a04518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total = pd.concat([X_train, y_train], axis = 1)\n",
    "test_total = pd.concat([X_test, y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2ba23f",
   "metadata": {},
   "source": [
    "- Identify best parameters for vectorizer. Code credit to lesson 'advanced hyperparameter search'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae1ed1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words = 'english')),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'cvec__max_features': Integer(5000, 10000),\n",
    "    'cvec__min_df': Integer(1, 5),\n",
    "    'cvec__max_df': Real(.75,1, prior='uniform')\n",
    "    #'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "cvec_bs = BayesSearchCV(estimator = pipe,\n",
    "                     search_spaces = params,\n",
    "                     scoring = 'f1_weighted',\n",
    "                     n_iter = 50,\n",
    "                     cv = 5,\n",
    "                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "277a3ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=5,\n",
       "              estimator=Pipeline(steps=[('cvec',\n",
       "                                         CountVectorizer(stop_words='english')),\n",
       "                                        ('mnb', MultinomialNB())]),\n",
       "              random_state=42, scoring='f1_weighted',\n",
       "              search_spaces={'cvec__max_df': Real(low=0.75, high=1, prior='uniform', transform='identity'),\n",
       "                             'cvec__max_features': Integer(low=5000, high=10000, prior='uniform', transform='identity'),\n",
       "                             'cvec__min_df': Integer(low=1, high=5, prior='uniform', transform='identity')})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec_bs.fit(X_train['post_text'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0997b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cvec_bs.predict(X_test['post_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c6134b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 CountVectorizer(max_df=0.7591845371145763, max_features=9916,\n",
       "                                 min_df=2, stop_words='english')),\n",
       "                ('mnb', MultinomialNB())])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec_bs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3420afb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d2f748d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7783115991763898,\n",
       " 'sensitivity': 0.6802827965435978,\n",
       " 'specificity': 0.8543570993296771,\n",
       " 'f1': 0.7283431455004206}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(tn, fp, fn, tp, metric = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45185e76",
   "metadata": {},
   "source": [
    "- Vectorize words and add to dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40fde493",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = cvec_bs.best_estimator_['cvec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a10e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcv_train = cvec.fit_transform(train_total['post_text'])\n",
    "Xcv_test = cvec.transform(test_total['post_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4da02728",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xcv_train = pd.DataFrame(Xcv_train.todense(), columns = cvec.get_feature_names())\n",
    "df_xcv_test = pd.DataFrame(Xcv_test.todense(), columns = cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aea59518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xcv_train.reset_index(inplace = True)\n",
    "df_xcv_test.reset_index(inplace = True)\n",
    "train_total.reset_index(inplace = True)\n",
    "test_total.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48d1dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_vecs = pd.concat([train_total, df_xcv_train], axis = 1)\n",
    "test_with_vecs = pd.concat([test_total, df_xcv_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50349c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_with_vecs, test_with_vecs], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5473718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c436c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'index', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedf20e3",
   "metadata": {},
   "source": [
    "- Save engineered file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d7bdf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/engineered_cmv&unpop_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c785d2",
   "metadata": {},
   "source": [
    "- On to part 4 ->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
